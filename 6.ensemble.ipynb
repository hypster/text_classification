{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from util import corpus_to_df,read_corpus\n",
    "import numpy as np\n",
    "from joblib import Memory\n",
    "from shutil import rmtree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import path\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pydotplus.graphviz import graph_from_dot_data\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import BaggingClassifier,VotingClassifier,AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def document(corpus):\n",
    "    return (corpus.raw(id) for id in corpus.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 3884)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_en_cleaned,corpus_nl_cleaned,corpus_cleaned = read_corpus()\n",
    "len(corpus_en_cleaned.fileids()), len(corpus_nl_cleaned.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>innov</th>\n",
       "      <th>innov_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en/innov/10000232.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>innov</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en/innov/10000364.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>innov</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en/innov/10010653.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>innov</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en/innov/10013385.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>innov</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en/innov/10025316.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>innov</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id lang  innov  innov_\n",
       "0  en/innov/10000232.txt   en  innov       1\n",
       "1  en/innov/10000364.txt   en  innov       1\n",
       "2  en/innov/10010653.txt   en  innov       1\n",
       "3  en/innov/10013385.txt   en  innov       1\n",
       "4  en/innov/10025316.txt   en  innov       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = corpus_to_df(corpus_cleaned)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['innov_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vec = CountVectorizer(min_df = 2, max_df = 0.95,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = c_vec.fit_transform(document(corpus_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = SelectKBest(chi2,k=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = select.fit_transform(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, stratify = y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4337, 2000), (4337,))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.toarray().shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(c_vec.get_feature_names())[select.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_data = export_graphviz(                           # Create dot data\n",
    "#     clf, filled=True, rounded=True,\n",
    "#     class_names=['other', 'innov'],\n",
    "#     feature_names= feature_names,\n",
    "#     out_file=None\n",
    "# )\n",
    "\n",
    "# graph = graph_from_dot_data(dot_data)                 # Create graph from dot data\n",
    "# graph.write_png('tree.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.50      0.49       219\n",
      "           1       0.57      0.56      0.56       263\n",
      "\n",
      "    accuracy                           0.53       482\n",
      "   macro avg       0.53      0.53      0.53       482\n",
      "weighted avg       0.53      0.53      0.53       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = BaggingClassifier(clf, n_estimators=100,random_state = 42, bootstrap_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                        class_weight=None,\n",
       "                                                        criterion='entropy',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort='deprecated',\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=True, max_features=1.0,\n",
       "                  max_samples=1.0, n_estimators=100, n_jobs=None,\n",
       "                  oob_score=False, random_state=42, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.47      0.53       219\n",
      "           1       0.63      0.75      0.68       263\n",
      "\n",
      "    accuracy                           0.62       482\n",
      "   macro avg       0.61      0.61      0.60       482\n",
      "weighted avg       0.62      0.62      0.61       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, ens.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_p = Pipeline([\n",
    "    ('vec', CountVectorizer(min_df = 2, max_df = 0.95,binary=True)),\n",
    "    ('clf', BaggingClassifier(DecisionTreeClassifier(criterion='entropy'), n_estimators=100,max_samples=0.5,max_features=0.1, n_jobs=-1, random_state = 42))    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, stratify = df['innov'], test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_document(ids, corpus):\n",
    "    return [corpus.raw(id) for id in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vec',\n",
       "                 CountVectorizer(analyzer='word', binary=True,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.95,\n",
       "                                 max_features=None, min_df=2,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None...\n",
       "                                                                         min_impurity_decrease=0.0,\n",
       "                                                                         min_impurity_split=None,\n",
       "                                                                         min_samples_leaf=1,\n",
       "                                                                         min_samples_split=2,\n",
       "                                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                                         presort='deprecated',\n",
       "                                                                         random_state=None,\n",
       "                                                                         splitter='best'),\n",
       "                                   bootstrap=True, bootstrap_features=False,\n",
       "                                   max_features=0.1, max_samples=0.5,\n",
       "                                   n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                                   random_state=42, verbose=0,\n",
       "                                   warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_p.fit(read_document(df_train['id'],corpus_cleaned), df_train['innov_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       other       0.61      0.54      0.58       219\n",
      "       innov       0.65      0.71      0.68       263\n",
      "\n",
      "    accuracy                           0.64       482\n",
      "   macro avg       0.63      0.63      0.63       482\n",
      "weighted avg       0.63      0.64      0.63       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test['innov_'],clf_p.predict(read_document(df_test['id'],corpus_cleaned)),target_names=['other','innov']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf_p, read_document(df_test['id'],corpus_cleaned), df_test['innov_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5933848797250859, 0.03204382421048147)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ensemble.pickle', 'wb') as f:\n",
    "    pickle.dump(clf_p, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_p2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 2, max_df = 0.95)),\n",
    "    ('clf', BaggingClassifier(DecisionTreeClassifier(criterion='entropy'), n_estimators=100,max_samples=0.5,max_features=0.1, n_jobs=-1, random_state = 42))    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.95, max_features=None,\n",
       "                                 min_df=2, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern=...\n",
       "                                                                         min_impurity_decrease=0.0,\n",
       "                                                                         min_impurity_split=None,\n",
       "                                                                         min_samples_leaf=1,\n",
       "                                                                         min_samples_split=2,\n",
       "                                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                                         presort='deprecated',\n",
       "                                                                         random_state=None,\n",
       "                                                                         splitter='best'),\n",
       "                                   bootstrap=True, bootstrap_features=False,\n",
       "                                   max_features=0.1, max_samples=0.5,\n",
       "                                   n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                                   random_state=42, verbose=0,\n",
       "                                   warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_p2.fit(read_document(df_train['id'],corpus_cleaned), df_train['innov_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       other       0.62      0.54      0.58       219\n",
      "       innov       0.65      0.72      0.69       263\n",
      "\n",
      "    accuracy                           0.64       482\n",
      "   macro avg       0.64      0.63      0.63       482\n",
      "weighted avg       0.64      0.64      0.64       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test['innov_'],clf_p2.predict(read_document(df_test['id'],corpus_cleaned)),target_names=['other','innov']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = clf_p[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = _.estimators_features_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transform = clf_p[0].transform(read_document(df_train['id'], corpus_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = clf_p[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 13871)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(_.estimators_features_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = []\n",
    "for f in clf_p[1].estimators_features_:\n",
    "    names = f[:5]\n",
    "    all_names.extend(np.array(clf_p[0].get_feature_names())[names])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = np.array(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(random_state=42)),\n",
    "    ('rf', clf_p2[1]),\n",
    "    ('mnb', MultinomialNB())\n",
    "], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_p3 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 2, max_df = 0.95)),\n",
    "    ('clf', voting)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEID</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>innov</th>\n",
       "      <th>innov_</th>\n",
       "      <th>word_count</th>\n",
       "      <th>text_length</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>URL</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000232</td>\n",
       "      <td>en/innov/10000232.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>innov</td>\n",
       "      <td>1</td>\n",
       "      <td>8520</td>\n",
       "      <td>49903</td>\n",
       "      <td>5.857160</td>\n",
       "      <td>http://www.vdlbuscoach.com/</td>\n",
       "      <td>expertis travel travel ever experi motto make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000364</td>\n",
       "      <td>en/innov/10000364.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>innov</td>\n",
       "      <td>1</td>\n",
       "      <td>11801</td>\n",
       "      <td>68869</td>\n",
       "      <td>5.835861</td>\n",
       "      <td>https://www.stork.com/en/products-services/pow...</td>\n",
       "      <td>gear servic stork gear servic stork gear servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10010653</td>\n",
       "      <td>en/innov/10010653.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>innov</td>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>1877</td>\n",
       "      <td>5.032172</td>\n",
       "      <td>http://www.oriental-city.com/</td>\n",
       "      <td>boekingsbureau orient citi zeven dagen per wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10013385</td>\n",
       "      <td>en/innov/10013385.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>innov</td>\n",
       "      <td>1</td>\n",
       "      <td>2889</td>\n",
       "      <td>18845</td>\n",
       "      <td>6.523018</td>\n",
       "      <td>https://www.honeywell-buildingsolutions.nl/</td>\n",
       "      <td>cybersecur honeywel comfortpoint open ​airport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10025316</td>\n",
       "      <td>en/innov/10025316.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>innov</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>564</td>\n",
       "      <td>5.529412</td>\n",
       "      <td>http://www.winteb.nl/contact/</td>\n",
       "      <td>product servic win hia wiko type wiko goosenec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BEID                     id lang  innov  innov_  word_count  \\\n",
       "0  10000232  en/innov/10000232.txt   en  innov       1        8520   \n",
       "1  10000364  en/innov/10000364.txt   en  innov       1       11801   \n",
       "2  10010653  en/innov/10010653.txt   en  innov       1         373   \n",
       "3  10013385  en/innov/10013385.txt   en  innov       1        2889   \n",
       "4  10025316  en/innov/10025316.txt   en  innov       1         102   \n",
       "\n",
       "   text_length  avg_word_len  \\\n",
       "0        49903      5.857160   \n",
       "1        68869      5.835861   \n",
       "2         1877      5.032172   \n",
       "3        18845      6.523018   \n",
       "4          564      5.529412   \n",
       "\n",
       "                                                 URL  \\\n",
       "0                        http://www.vdlbuscoach.com/   \n",
       "1  https://www.stork.com/en/products-services/pow...   \n",
       "2                      http://www.oriental-city.com/   \n",
       "3        https://www.honeywell-buildingsolutions.nl/   \n",
       "4                      http://www.winteb.nl/contact/   \n",
       "\n",
       "                                                text  \n",
       "0  expertis travel travel ever experi motto make ...  \n",
       "1  gear servic stork gear servic stork gear servi...  \n",
       "2  boekingsbureau orient citi zeven dagen per wee...  \n",
       "3  cybersecur honeywel comfortpoint open ​airport...  \n",
       "4  product servic win hia wiko type wiko goosenec...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_cleaned = read_corpus('/Users/septem/Downloads/companies_cleaned/')[2]\n",
    "df = pd.read_csv('./companies.csv')\n",
    "from scipy import stats\n",
    "df = df[np.abs(stats.zscore(df['text_length'])) < 3]\n",
    "df['text'] = [corpus_cleaned.raw(id) for id in df['id']]\n",
    "df = df[df['lang'] != 'rest']\n",
    "onehot = OneHotEncoder() \n",
    "scaler = MinMaxScaler()\n",
    "lang_feature = onehot.fit_transform([[lang] for lang in df['lang']])\n",
    "stat_feature = scaler.fit_transform(np.array(df[['avg_word_len']]))\n",
    "df_small = np.concatenate((lang_feature.toarray(), stat_feature,df['text'][:,np.newaxis]), axis = 1)\n",
    "df_small = pd.DataFrame(df_small)\n",
    "df_small = df_small.set_index(df.index)\n",
    "df_small['innov_'] = df['innov_']\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.index, df['innov_'], random_state = 42, stratify=df['innov_'], test_size = 0.1)\n",
    "x_train = df_small.loc[x_train]\n",
    "x_test = df_small.loc[x_test]\n",
    "x_train = x_train.drop(columns='innov_')\n",
    "x_test = x_test.drop(columns='innov_')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.28      0.39       216\n",
      "           1       0.59      0.87      0.70       261\n",
      "\n",
      "    accuracy                           0.60       477\n",
      "   macro avg       0.61      0.57      0.55       477\n",
      "weighted avg       0.61      0.60      0.56       477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "pipe = Pipeline([\n",
    "    ('union', ColumnTransformer([\n",
    "        ('vect', Pipeline([\n",
    "            ('tfidf',TfidfVectorizer()),\n",
    "            ('select', SelectKBest(f_classif, k = 20000))\n",
    "        ]), 3),\n",
    "    ], remainder='passthrough')),\n",
    "    \n",
    "    ('clf', VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(C=1,max_iter=1000, solver='liblinear', penalty='l2', random_state=42)),\n",
    "    ('svm', LinearSVC()),\n",
    "    ('rf', clf_p2[1]),\n",
    "    ('mnb', MultinomialNB())\n",
    "], voting = 'soft'))\n",
    "])\n",
    "pipe.fit(x_train, y_train)\n",
    "print(classification_report(y_test, pipe.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.37      0.47       216\n",
      "           1       0.62      0.84      0.71       261\n",
      "\n",
      "    accuracy                           0.62       477\n",
      "   macro avg       0.63      0.60      0.59       477\n",
      "weighted avg       0.63      0.62      0.60       477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_p3.fit(x_train[3], y_train)\n",
    "print(classification_report(y_test, clf_p3.predict(x_test[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.95, max_features=None,\n",
       "                                 min_df=2, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern=...\n",
       "                                                                                                       presort='deprecated',\n",
       "                                                                                                       random_state=None,\n",
       "                                                                                                       splitter='best'),\n",
       "                                                                 bootstrap=True,\n",
       "                                                                 bootstrap_features=False,\n",
       "                                                                 max_features=0.1,\n",
       "                                                                 max_samples=0.5,\n",
       "                                                                 n_estimators=100,\n",
       "                                                                 n_jobs=-1,\n",
       "                                                                 oob_score=False,\n",
       "                                                                 random_state=42,\n",
       "                                                                 verbose=0,\n",
       "                                                                 warm_start=False)),\n",
       "                                              ('mnb',\n",
       "                                               MultinomialNB(alpha=1.0,\n",
       "                                                             class_prior=None,\n",
       "                                                             fit_prior=True))],\n",
       "                                  flatten_transform=True, n_jobs=None,\n",
       "                                  voting='soft', weights=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_p3.fit(read_document(df_train['id'],corpus_cleaned), df_train['innov_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       other       0.75      0.35      0.47       219\n",
      "       innov       0.62      0.90      0.74       263\n",
      "\n",
      "    accuracy                           0.65       482\n",
      "   macro avg       0.69      0.63      0.61       482\n",
      "weighted avg       0.68      0.65      0.62       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test['innov_'],clf_p3.predict(read_document(df_test['id'],corpus_cleaned)),target_names=['other','innov']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('select', SelectKBest(f_classif, 20000)),\n",
    "    ('lg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([\n",
    "    ('union', ColumnTransformer([\n",
    "        ('vect', Pipeline([\n",
    "            ('tfidf',TfidfVectorizer(min_df=2,max_df=0.8)),\n",
    "            ('select', SelectKBest(f_classif, k = 20000))\n",
    "        ]), 3),\n",
    "    ], remainder='passthrough')),\n",
    "    ('clf', LogisticRegression(C=1,max_iter=1000, solver='liblinear', penalty='l2', random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(corpus_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                                 vocabulary=None)),\n",
       "                ('select',\n",
       "                 SelectKBest(k=20000,\n",
       "                             score_func=<function f_classif at 0x1a3056c950>)),\n",
       "                ('lg',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "        'ngram_range' : (1,1),\n",
    "        'dtype' : 'int32',\n",
    "        'strip_accents' : 'unicode',\n",
    "        'decode_error' : 'replace',\n",
    "        'analyzer' : 'word',\n",
    "        'min_df' : 2,\n",
    "        'max_df' : 0.95\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1813: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.47      0.53       218\n",
      "           1       0.63      0.75      0.69       264\n",
      "\n",
      "    accuracy                           0.63       482\n",
      "   macro avg       0.62      0.61      0.61       482\n",
      "weighted avg       0.62      0.63      0.62       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p4 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(**kwargs)),\n",
    "    ('select', SelectKBest(f_classif, 20000)),\n",
    "    ('lg', LogisticRegression(solver='liblinear', C=1, penalty='l2',max_iter=1000, random_state=42))\n",
    "])\n",
    "x_train ,x_test, y_train, y_test = split_data(corpus_cleaned)\n",
    "p4.fit(x_train, y_train)\n",
    "print(classification_report(y_test, p4.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1813: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.49      0.55       218\n",
      "           1       0.64      0.76      0.70       264\n",
      "\n",
      "    accuracy                           0.64       482\n",
      "   macro avg       0.64      0.63      0.62       482\n",
      "weighted avg       0.64      0.64      0.63       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p4 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(**kwargs)),\n",
    "    ('lg', LogisticRegression(solver='liblinear', C=1, penalty='l2',max_iter=1000,random_state=42))\n",
    "])\n",
    "x_train ,x_test, y_train, y_test = split_data(corpus_cleaned)\n",
    "p4.fit(x_train, y_train)\n",
    "print(classification_report(y_test, p4.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1813: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.46      0.53       219\n",
      "           1       0.63      0.79      0.70       263\n",
      "\n",
      "    accuracy                           0.64       482\n",
      "   macro avg       0.64      0.62      0.62       482\n",
      "weighted avg       0.64      0.64      0.63       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p4 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(**kwargs)),\n",
    "    ('lg', LogisticRegression(solver='liblinear', C=1, penalty='l2',max_iter=1000,random_state=42))\n",
    "])\n",
    "x_train ,x_test, y_train, y_test = split_data(corpus_cleaned)\n",
    "p4.fit(x_train, y_train)\n",
    "print(classification_report(y_test, p4.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_params = dict(\n",
    "    tfidf__max_df = [0.85,0.9,0.95],\n",
    "#     tfidf__min_df = [2,5,10],\n",
    "#     ngram_range = [(1,1),(1,2)],\n",
    "    lg__C = np.logspace(-1,4,5),\n",
    "    lg__penalty = ['l1', 'l2'],\n",
    "#     lg__max_iter = [20,40,100]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': [0.85, 0.9, 0.95],\n",
       " 'lg__C': array([1.00000000e-01, 1.77827941e+00, 3.16227766e+01, 5.62341325e+02,\n",
       "        1.00000000e+04]),\n",
       " 'lg__penalty': ['l1', 'l2']}"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(p4, param_grid = tuning_params, n_jobs = -1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 44.6min finished\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1813: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from joblib import Memory\n",
    "from shutil import rmtree\n",
    "location = 'cachedir'\n",
    "memory = Memory(location=location, verbose=10)\n",
    "x_train ,x_test, y_train, y_test = split_data(corpus_cleaned)\n",
    "grid.fit(list(x_train), y_train)\n",
    "memory.clear(warn=False)\n",
    "rmtree(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lg__C': 1.7782794100389228, 'lg__penalty': 'l2', 'tfidf__max_df': 0.85}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.48      0.54       219\n",
      "           1       0.64      0.76      0.70       263\n",
      "\n",
      "    accuracy                           0.63       482\n",
      "   macro avg       0.63      0.62      0.62       482\n",
      "weighted avg       0.63      0.63      0.63       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train ,x_test, y_train, y_test = split_data(corpus_cleaned)\n",
    "print(classification_report(y_test,grid.best_estimator_.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(corpus):\n",
    "    df = corpus_to_df(corpus)\n",
    "    x = [corpus.raw(id) for id in df['id']]\n",
    "    y = df['innov_']\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='replace', dtype='int32',\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.85, max_features=None,\n",
       "                                 min_df=2, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents='unicode',\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('lg',\n",
       "                 LogisticRegression(C=1.7782794100389228, class_weight=None,\n",
       "                                    dual=False, fit_intercept=True,\n",
       "                                    intercept_scaling=1, l1_ratio=None,\n",
       "                                    max_iter=1000, multi_class='auto',\n",
       "                                    n_jobs=None, penalty='l2', random_state=42,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1813: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "x,y = make_data(corpus_cleaned)\n",
    "scores = cross_val_score(grid.best_estimator_, x,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6109129061585726, 0.0148606506934016)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "p5 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(**kwargs)),\n",
    "    ('lg', LogisticRegression(solver='liblinear', C=1, penalty='l2',max_iter=1000,random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='replace', dtype='int32',\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.85, max_features=None,\n",
       "                                 min_df=2, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents='unicode',\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('lg',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=1000,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=42,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p5.set_params(**grid.best_params_)\n",
    "p5.set_params(lg__C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1813: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.46      0.53       219\n",
      "           1       0.63      0.79      0.70       263\n",
      "\n",
      "    accuracy                           0.64       482\n",
      "   macro avg       0.64      0.62      0.62       482\n",
      "weighted avg       0.64      0.64      0.63       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train ,x_test, y_train, y_test = split_data(corpus_cleaned)\n",
    "p5.fit(x_train, y_train)\n",
    "print(classification_report(y_test, p5.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1813: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(p5, x,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2629\n",
       "0    2190\n",
       "Name: innov_, dtype: int64"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6131999378887346, 0.030039770128867514)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores),np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf_lg_model.pickle', 'wb') as f:\n",
    "    pickle.dump(p5, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('pickle/tfidf_lg_model.pickle','rb') as f:\n",
    "    p5 = pickle.load(f)\n",
    "p5 = GridSearchCV(p5,   param_grid= {\n",
    "    'tfidf__min_df': [2,4,8],\n",
    "    'tfidf__max_df': [0.75,0.8,0.85]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1813: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "location = 'cachedir'\n",
    "memory = Memory(location=location, verbose=10)\n",
    "x_train ,x_test, y_train, y_test = split_data(corpus_cleaned)\n",
    "p5.fit(list(x_train), y_train)\n",
    "memory.clear(warn=False)\n",
    "rmtree(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.75, 'tfidf__min_df': 4}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='replace', dtype='int32',\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.75, max_features=None,\n",
       "                                 min_df=4, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents='unicode',\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('lg',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=1000,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=42,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1813: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.48      0.55       219\n",
      "           1       0.64      0.77      0.70       263\n",
      "\n",
      "    accuracy                           0.64       482\n",
      "   macro avg       0.64      0.63      0.62       482\n",
      "weighted avg       0.64      0.64      0.63       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train ,x_test, y_train, y_test = split_data(corpus_cleaned)\n",
    "p5.best_estimator_.fit(x_train, y_train)\n",
    "print(classification_report(y_test, p5.best_estimator_.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/tfidf_lg_model.pickle','wb') as f:\n",
    "    pickle.dump(p5.best_estimator_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "with open ('pickle/tfidf_lg_model.pickle','rb') as f:\n",
    "    p5 = pickle.load(f)\n",
    "p5 = GridSearchCV(p5,   param_grid= {\n",
    "    'tfidf__max_df': [0.65,0.7,0.75]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1813: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "location = 'cachedir'\n",
    "memory = Memory(location=location, verbose=10)\n",
    "x_train ,x_test, y_train, y_test = split_data(corpus_cleaned)\n",
    "p5.fit(list(x_train), y_train)\n",
    "memory.clear(warn=False)\n",
    "rmtree(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='replace', dtype='int32',\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.75, max_features=None,\n",
       "                                 min_df=4, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents='unicode',\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('lg',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=1000,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=42,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = p5.best_estimator_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "p6 = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('select', SelectKBest(k=1000)),\n",
    "    ('ada', AdaBoostClassifier(n_estimators=100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1813: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.48      0.52       219\n",
      "           1       0.61      0.69      0.65       263\n",
      "\n",
      "    accuracy                           0.59       482\n",
      "   macro avg       0.59      0.58      0.58       482\n",
      "weighted avg       0.59      0.59      0.59       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test, y_train, y_test = split_data(corpus_cleaned)\n",
    "p6.fit(x_train, y_train)\n",
    "print(classification_report(y_test, p6.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-13d876780abb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'bag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'mnb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m ], voting = 'soft')\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'estimators'"
     ]
    }
   ],
   "source": [
    "boosting = AdaBoostClassifier(estimators=[\n",
    "    ('lr', p5.best_estimator_.named_steps.lg),\n",
    "    ('bag', BaggingClassifier(DecisionTreeClassifier(criterion='entropy'), n_estimators=100,max_samples=0.5,max_features=0.1, n_jobs=-1, random_state = 42)),\n",
    "    ('mnb', MultinomialNB())\n",
    "], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57       219\n",
      "           1       0.65      0.74      0.69       263\n",
      "\n",
      "    accuracy                           0.64       482\n",
      "   macro avg       0.64      0.63      0.63       482\n",
      "weighted avg       0.64      0.64      0.64       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test, y_train, y_test = split_data(corpus_cleaned)\n",
    "p7 = Pipeline([\n",
    "    ('count', CountVectorizer(max_df=0.9,\n",
    "    min_df=4,\n",
    "    max_features=None,\n",
    "    binary=True)), \n",
    "    ('ada', AdaBoostClassifier(base_estimator=p5.best_estimator_.named_steps.lg, n_estimators=30))\n",
    "])\n",
    "p7.fit(x_train, y_train)\n",
    "print(classification_report(y_test, p7.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1813: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.43      0.52       219\n",
      "           1       0.63      0.79      0.70       263\n",
      "\n",
      "    accuracy                           0.63       482\n",
      "   macro avg       0.63      0.61      0.61       482\n",
      "weighted avg       0.63      0.63      0.62       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test, y_train, y_test = split_data(corpus_cleaned)\n",
    "voting = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(C=1, random_state=42)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42, max_features=0.5)),\n",
    "    ('mnb',MultinomialNB())\n",
    "], voting= 'soft', weights=[1,2,1])\n",
    "    \n",
    "p7 = Pipeline([\n",
    "    ('tfidf', tfidf), \n",
    "    ('voting', voting)\n",
    "])\n",
    "p7.fit(x_train, y_train)\n",
    "print(classification_report(y_test, p7.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
