{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import CategorizedPlaintextCorpusReader\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "# project module\n",
    "from benchmark import get_benchmark, plot_confusion_matrix\n",
    "from yellowbrick.text import FreqDistVisualizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from os import path\n",
    "import os\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import learning_curve\n",
    "from util import corpus_to_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification with BERT in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018 was an exciting year for Natural Language Processing. One of the most promising evolutions was the breakthrough of transfer learning. Models like Elmo Embeddings, ULMFit and BERT allow us to pre-train a neural network on a large collection of unlabelled texts. Thanks to an auxiliary task such as language modelling, these models are able to learn a lot about the syntax, semantics and morphology of a language. This knowledge can be put to good use: because they already know so much about language use, these models need much less labelled data to reach state-of-the-art performance on other tasks, such as text classification, sequence labelling or question answering. \n",
    "\n",
    "One of the most popular models is [BERT](https://arxiv.org/abs/1810.04805), developed by researchers at Google. BERT stands for Bidirectional Encoder Representations from Transformers. It uses the Transformer architecture to pretrain bidirectional \"language models\". By adding just one task-specific output layer, it is possible to use such a pre-trained BERT model on a variety of NLP tasks. In this notebook, we're going to investigate its performance on a sentiment analysis task, where the task is to predict whether a review is positive or negative. Unfortunately, we can't share the data, but you can easily plug in your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first get our data. Our corpus is a simple newline-delimited json file with a list of product reviews from Amazon. It's a subset of the huge [Amazon review corpus](https://nijianmo.github.io/amazon/index.html) that has been so popular in sentiment analysis. Each of the documents in our file is a dictionary with a \"title\", \"body\" and \"rating\". We'll try to build a model that can predict the rating from the title and the body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_PATH = \"data/sentiment_analysis/review_corpus_en.ndjson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we split up the data into a train, development and test portion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3dbc62e4699f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorpus_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorizedPlaintextCorpusReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/septem/Downloads/companies2/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_en_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_nl_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_en_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/dke/2/ke@work/code_for_ke@work/util.py\u001b[0m in \u001b[0;36mcorpus_to_df\u001b[0;34m(corpus, language)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minnov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minnov\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lang'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'innov'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "doc_pattern = r'.*\\.txt';\n",
    "cat_pattern = r'([\\w_/]+)/.*';\n",
    "corpus_en_cleaned =CategorizedPlaintextCorpusReader('/Users/septem/Downloads/companies2/en/', doc_pattern, cat_pattern=cat_pattern)\n",
    "corpus_nl_cleaned =CategorizedPlaintextCorpusReader('/Users/septem/Downloads/companies2/nl/', doc_pattern, cat_pattern=cat_pattern)\n",
    "corpus_cleaned = CategorizedPlaintextCorpusReader('/Users/septem/Downloads/companies2/', doc_pattern, cat_pattern = cat_pattern)\n",
    "len(corpus_en_cleaned.fileids()), len(corpus_nl_cleaned.fileids())\n",
    "df = corpus_to_df(corpus_en_cleaned)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4021\n",
      "Dev size: 447\n",
      "Test size: 497\n"
     ]
    }
   ],
   "source": [
    "# import ndjson\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# with open(CORPUS_PATH) as i:\n",
    "#     data = ndjson.load(i)\n",
    "\n",
    "\n",
    "# texts = [\" \".join([doc[\"title\"], doc[\"body\"]]) for doc in data]\n",
    "# labels = [doc[\"rating\"] for doc in data]\n",
    "\n",
    "texts = [corpus_cleaned.raw(id) for id in df['id']]\n",
    "labels = df['innov']\n",
    "\n",
    "\n",
    "rest_texts, test_texts, rest_labels, test_labels = train_test_split(texts, labels, test_size=0.1, random_state=1)\n",
    "train_texts, dev_texts, train_labels, dev_labels = train_test_split(rest_texts, rest_labels, test_size=0.1, random_state=1)\n",
    "\n",
    "print(\"Train size:\", len(train_texts))\n",
    "print(\"Dev size:\", len(dev_texts))\n",
    "print(\"Test size:\", len(test_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to determine the number of labels in our data. We'll map each of these labels to an index. In our sentiment analysis example, there are three labels: positive (all 4-star and 5-star reviews), mixed (all 3-star reviews) and negative (all 2-star and 1-star reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'others': 0, 'innov': 1}\n"
     ]
    }
   ],
   "source": [
    "target_names = list(set(labels))\n",
    "label2idx = {label: idx for idx, label in enumerate(target_names)}\n",
    "print(label2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "Let's train a baseline model for our task. In this way we have something to compare BERT's performance to. As our baseline, we choose a simple Logistic Regression classifier from Scikit-learn. We use grid search to find the optimal settings for its hyperparameter _C_. At the end of this process, we find that our best baseline classifier obtains an accuracy of 62.67%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 16.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.6116700201207244\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('lr', LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "parameters = {'lr__C': [0.1, 0.5, 1, 2, 5, 10, 100, 1000]}\n",
    "\n",
    "best_classifier = GridSearchCV(pipeline, parameters, cv=5, verbose=1)\n",
    "best_classifier.fit(train_texts, train_labels)\n",
    "best_predictions = best_classifier.predict(test_texts)\n",
    "\n",
    "baseline_accuracy = np.mean(best_predictions == test_labels)\n",
    "print(\"Baseline accuracy:\", baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move to BERT. The team at [HuggingFace](https://github.com/huggingface) has developed a great Python library, [transformers](https://github.com/huggingface/transformers), with implementations of an impressive number of transfer-learning models in PyTorch and Tensorflow. It makes finetuning these models pretty easy. Let's first install this library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 2.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /Users/septem/anaconda3/lib/python3.6/site-packages (from transformers) (2018.6.21)\n",
      "Requirement already satisfied: numpy in /Users/septem/anaconda3/lib/python3.6/site-packages (from transformers) (1.17.4)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 24.1MB/s eta 0:00:01    |██                              | 51kB 19.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/10/68d949f03c994dbff789129107a2734db2313cace770008588dab51bc281/sentencepiece-0.1.85-cp36-cp36m-macosx_10_6_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 21.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/septem/anaconda3/lib/python3.6/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /Users/septem/anaconda3/lib/python3.6/site-packages (from transformers) (1.9.66)\n",
      "Requirement already satisfied: tqdm in /Users/septem/anaconda3/lib/python3.6/site-packages (from transformers) (4.39.0)\n",
      "Requirement already satisfied: six in /Users/septem/anaconda3/lib/python3.6/site-packages (from sacremoses->transformers) (1.13.0)\n",
      "Requirement already satisfied: click in /Users/septem/anaconda3/lib/python3.6/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /Users/septem/anaconda3/lib/python3.6/site-packages (from sacremoses->transformers) (0.14.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/septem/anaconda3/lib/python3.6/site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/septem/anaconda3/lib/python3.6/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/septem/anaconda3/lib/python3.6/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/septem/anaconda3/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.66 in /Users/septem/anaconda3/lib/python3.6/site-packages (from boto3->transformers) (1.12.189)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/septem/anaconda3/lib/python3.6/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /Users/septem/anaconda3/lib/python3.6/site-packages (from boto3->transformers) (0.1.13)\n",
      "Requirement already satisfied: docutils>=0.10 in /Users/septem/anaconda3/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.66->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/septem/anaconda3/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.66->boto3->transformers) (2.8.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=9c32135f6046347b51298071526be35c42d7ae41b156dfbaad71ff573454e703\n",
      "  Stored in directory: /Users/septem/Library/Caches/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You really need a GPU to finetune BERT. Still, to make sure this code runs on any machine we'll let PyTorch determine whether a GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google has made available a range of BERT models for us to experiment with. For English, there is a choice between three models: `bert-large-uncased` is the largest model that will likely give the best results. Its smaller siblings are `bert-base-uncased` and `bert-base-cased`, which are more practical to work with. For Chinese there is `bert-base-chinese`, and for the other languages we have `bert-base-multilingual-uncased` and `bert-base-multilingual-cased`. \n",
    "\n",
    "Uncased means that the training text has been lowercased and accents have been stripped. This is usually better, unless you know that case information is important for your task, such as with Named Entity Recognition. \n",
    "\n",
    "In our example, we're going to investigate sentiment analysis on English. We'll therefore use the English BERT-base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each model comes with its own tokenizer. This tokenizer splits texts into [word pieces](https://github.com/google/sentencepiece). In addition, we'll tell the tokenizer it should lowercase the text, as we're going to work with the uncased model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers.tokenization_bert import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full BERT model consists of a common, pretrained core, and an extension on top that depends on the particular NLP task. After all, the output of a sequence classification model, where we have just one prediction for every sequence, looks very different from the output of a sequence labelling or question answering model. As we're looking at sentiment classification, we're going to use the pretrained BERT model with a final layer for sequence classification on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.modeling_bert import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, num_labels = len(label2idx))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to prepare our data for BERT. We'll present every document as a BertInputItem object, which contains all the information BERT needs: \n",
    "\n",
    "- a list of input ids. Take a look at the logging output to see what this means. Every text has been split up into subword units, which are shared between all the languages in the multilingual model. When a word appears frequently enough in a combined corpus of all languages, it is kept intact. If it is less frequent, it is split up into subword units that do occur frequently enough across all languages. This allows our model to process every text as a sequence of strings from a finite vocabulary of limited size. Note also the first `[CLS]` token. This token is added at the beginning of every document. The vector at the output of this token will be used by the BERT model for its sequence classification tasks: it serves as the input of the final, task-specific part of the neural network.\n",
    "- the input mask: the input mask tells the model which parts of the input it should look at and which parts it should ignore. In our example, we have made sure that every text has a length of 100 tokens. This means that some texts will be cut off after 100 tokens, while others will have to be padded with extra tokens. In this latter case, these padding tokens will receive a mask value of 0, which means BERT should not take them into account for its classification task. \n",
    "- the segment_ids: some NLP task take several sequences as input. This is the case for question answering, natural language inference, etc. In this case, the segment ids tell BERT which sequence every token belongs to. In a text classification task like ours, however, there's only one segment, so all the input tokens receive segment id 0.\n",
    "- the label id: the id of the label for this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:56:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27315 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17456 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (940 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3651 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27803 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31158 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35124 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41406 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28650 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2858 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25844 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37448 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10743 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12196 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39053 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1689 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23691 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2618 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29788 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9327 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2059 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40758 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3621 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20153 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13003 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8462 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:56:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11429 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26557 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8525 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10564 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6035 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39329 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6137 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30824 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15976 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26666 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1644 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4342 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22766 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3297 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13451 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31691 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5449 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31122 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29467 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33900 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24110 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38331 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15269 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4194 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6459 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9587 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6357 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7514 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40254 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41668 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36690 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5749 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:56:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5704 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32141 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13144 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5614 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13072 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6953 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29653 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16374 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38230 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43083 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29208 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9598 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38564 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5992 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17908 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40125 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32972 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11798 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31369 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28733 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6238 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34883 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8210 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27080 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24638 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23374 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4066 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42994 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7231 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3763 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:56:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26091 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5284 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9290 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35542 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2775 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6328 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23926 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17840 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13589 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8261 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16852 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9313 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4752 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11237 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40756 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21851 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2351 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:56:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20500 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8909 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30235 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7949 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9853 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36258 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8316 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (956 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2916 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15470 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:57:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2352 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12279 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3734 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5489 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17635 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3771 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2653 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1833 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (44806 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4334 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1531 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34062 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9073 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2100 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18217 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36709 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (44173 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (910 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2450 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24280 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5944 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2532 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33705 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20312 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11527 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20746 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37050 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4119 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5119 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6200 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21654 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14832 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:57:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11355 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5122 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29052 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29025 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2544 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20123 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23734 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2798 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34160 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35680 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8814 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15349 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32803 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25920 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7345 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38129 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6014 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2235 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10564 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14401 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2028 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2769 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8144 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4773 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:57:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41584 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2036 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28177 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12617 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3064 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38545 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17099 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19986 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38482 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5300 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13312 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29096 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5927 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33016 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39632 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14541 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27706 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4659 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43650 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1531 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4694 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1910 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1684 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17914 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20451 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3104 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32355 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22710 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:57:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15569 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17651 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24585 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28436 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26772 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4784 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2857 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19638 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11113 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11361 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8096 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (45550 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6829 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39927 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29083 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9693 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4066 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21398 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23242 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16340 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40556 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32304 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2766 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30214 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9522 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14531 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2147 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:57:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17771 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8381 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3857 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37076 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27272 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28889 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25001 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23085 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14102 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1939 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9277 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10941 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27280 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (938 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32623 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4387 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12131 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9246 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9798 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31987 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11024 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39114 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33174 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2119 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11587 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:57:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23926 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18942 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (975 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19692 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12379 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32038 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30212 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5375 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3966 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7446 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40120 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16416 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43152 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9683 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27530 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39477 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15664 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3277 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4176 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24430 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8704 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34697 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13671 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15756 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8144 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19030 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27570 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38407 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7558 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43731 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:57:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12557 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10999 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5302 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31748 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7138 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18994 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3081 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7918 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (65936 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7991 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4003 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25426 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (929 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35108 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26098 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1993 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7259 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2851 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11342 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8240 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9821 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13517 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18046 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27037 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9784 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2051 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33865 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10657 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3434 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42188 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41260 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:57:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3642 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:57:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5157 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1692 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23463 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3801 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9212 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37538 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10123 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1502 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1847 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25918 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8757 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4493 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1607 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6039 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23358 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21462 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29431 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10171 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22336 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (788 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17236 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4175 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6719 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13584 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33010 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23444 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:58:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33261 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32660 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12235 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2698 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26146 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18418 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1897 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8641 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25752 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18810 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35862 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19958 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (44430 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7742 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28779 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9914 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40289 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4066 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13395 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1801 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11998 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7161 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21604 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4785 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24734 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12550 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:58:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29215 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23149 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10731 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29995 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2303 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21420 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15330 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26704 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34225 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42585 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9654 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2272 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21409 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21472 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24799 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6502 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12604 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4066 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27429 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38084 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41073 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16064 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32556 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23613 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20303 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22455 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:58:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27564 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40526 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7060 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (882 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41655 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21249 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38797 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3634 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10177 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5255 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10550 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36036 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8982 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23102 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41082 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6063 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39649 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5333 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17811 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9737 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3397 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13661 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6193 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21553 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:58:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7454 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23081 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26241 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7148 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28410 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1980 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21783 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19896 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6516 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35102 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7415 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4311 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10365 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11571 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2333 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6455 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4176 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (45249 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26498 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6875 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23218 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20975 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33945 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4139 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22462 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7491 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5109 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2350 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:58:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5028 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14241 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8114 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12470 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17018 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29852 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38794 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18826 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31001 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18986 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11492 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32041 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26714 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2809 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3747 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34710 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12719 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25043 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3667 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26218 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10030 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33409 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2173 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8797 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19527 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12675 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18702 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:58:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3793 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7201 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3782 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19297 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42597 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20510 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27248 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15039 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16803 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9378 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14593 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34773 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38129 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16021 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28692 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14561 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4972 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10829 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15501 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (793 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1680 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2842 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21108 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8640 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8054 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:58:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (45525 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2613 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31622 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7217 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35015 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14910 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6386 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25452 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6718 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32293 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36527 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7854 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11037 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11791 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11535 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10854 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20289 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31677 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14684 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11089 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43841 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5933 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38105 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13863 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2721 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35507 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14543 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3160 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5461 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:58:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18605 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4765 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11776 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14947 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4118 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18079 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:58:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1622 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19209 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17016 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22540 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1554 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8624 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2320 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12616 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6487 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17914 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22040 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21192 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20713 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3352 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24213 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (66742 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15820 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19126 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2112 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:59:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28823 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36031 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3303 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22809 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2874 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15450 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3979 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29412 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30589 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28198 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1643 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11880 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41383 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31843 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5992 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2729 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21913 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36339 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39679 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4180 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8424 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1967 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15472 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18339 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5619 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41356 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4441 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:59:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15579 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35092 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17967 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7644 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3207 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2136 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30116 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1004 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28615 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36280 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36641 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2899 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12736 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6172 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (984 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29251 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (955 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25940 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9098 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40629 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15230 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2264 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8371 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6591 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16716 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8666 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21610 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29616 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10171 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:59:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2834 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37162 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3986 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15106 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7349 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24834 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2313 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18581 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42390 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4117 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41287 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9215 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9913 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3777 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22999 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3018 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8900 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19991 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1491 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3262 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35281 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17244 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43481 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16736 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42865 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1834 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3931 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20719 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:59:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2782 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (955 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35302 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22706 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39835 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3217 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28644 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10709 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26011 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32341 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6782 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12794 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14915 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2408 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19626 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43568 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (994 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25129 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1689 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4179 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25068 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8236 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22521 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (46757 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4523 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12728 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:59:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3456 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13384 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26132 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12454 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29576 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17951 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5443 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9147 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35342 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23094 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10131 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40284 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40847 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (951 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20756 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24397 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6617 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8060 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7957 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39905 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30178 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23452 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25288 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12273 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11342 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25478 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7709 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2074 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9033 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:59:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4161 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29299 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13445 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41897 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11867 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1986 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8480 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (908 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1898 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17906 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41961 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20364 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14257 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8965 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14056 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17779 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5187 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1543 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42145 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3247 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (923 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30221 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31638 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10149 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38139 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:59:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2001 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7934 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12784 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9554 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13779 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16673 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7083 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3457 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6076 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29324 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28830 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8733 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38658 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7513 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41595 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1792 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34136 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25921 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23564 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33744 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8248 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5890 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 12:59:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19924 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31955 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4930 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1605 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1744 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1856 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26135 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25300 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6787 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15701 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2909 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3320 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5088 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3304 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3193 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4160 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19934 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29561 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 12:59:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27190 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38493 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (860 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33822 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20151 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11573 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:00:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7583 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3344 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8305 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9045 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36479 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27127 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8135 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4721 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (51508 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21846 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22320 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13138 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39933 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21540 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (45992 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30271 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2761 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22827 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17189 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16181 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10902 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3884 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21981 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38895 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:00:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42025 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11598 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8619 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25100 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2334 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38855 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6517 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1904 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8171 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20527 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9874 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5568 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1910 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5250 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8146 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6633 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11538 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34297 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34720 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21584 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40936 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41024 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17914 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7161 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5340 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17941 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43729 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41536 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:00:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6734 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19408 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13924 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25307 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21979 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5257 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33957 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17818 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1900 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6561 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26350 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10540 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3239 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39198 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42620 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1818 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33784 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (949 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34149 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11348 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8642 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17982 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4659 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6747 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36591 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17683 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:00:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15575 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26577 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4617 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40420 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34028 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27446 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2105 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36970 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2756 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16294 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9821 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11753 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32483 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1006 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21099 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4540 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36486 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2461 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34988 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9324 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20716 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3464 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38672 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6393 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5869 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37224 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1014 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38181 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:00:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (853 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6777 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2624 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17398 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33257 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33120 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29373 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21168 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9066 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2992 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14741 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3827 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4087 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36694 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (44650 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9802 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8898 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4050 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5974 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30544 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5687 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3090 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4488 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36195 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8541 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35757 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (44461 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9843 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:00:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15502 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15100 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1856 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17352 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19576 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5878 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37238 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39999 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37554 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21513 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3102 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19574 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3146 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39921 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8262 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11765 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (921 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7877 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27555 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11038 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4301 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10295 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9023 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36680 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15465 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:00:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3877 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1717 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2216 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16982 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2826 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7291 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15512 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4546 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3868 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7266 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18724 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31278 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23157 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (905 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19057 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1802 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6820 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6104 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40773 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39020 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24986 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4152 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18602 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17138 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:00:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4733 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14918 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29673 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10556 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13903 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2566 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2592 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7051 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33914 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3584 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31294 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9944 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11408 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28167 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34468 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10659 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40980 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13232 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11887 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18702 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22575 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1999 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3873 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:00:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2787 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13520 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14218 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5966 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (875 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:00:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24497 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (49187 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16868 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4673 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10640 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24799 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1405 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36095 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31304 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14193 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23735 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2940 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18476 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5805 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21625 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42415 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17361 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12226 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35768 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24026 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6321 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13796 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2252 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:01:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8819 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7125 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2549 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8531 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3750 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28932 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2459 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25610 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25966 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41155 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5813 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21453 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22197 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6175 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32308 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13640 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18618 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19269 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4476 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39281 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28098 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33690 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31178 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5114 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17991 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7742 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1798 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33894 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:01:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20683 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41880 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35345 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17334 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28914 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25864 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31199 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22432 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2446 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20604 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5418 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31304 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2822 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3236 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2097 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34868 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21095 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14532 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22854 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8140 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30745 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (860 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21439 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3133 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10489 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1651 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37725 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30487 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4134 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25292 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13749 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:01:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22989 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2201 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19609 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4732 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5101 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40310 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8025 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26919 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20330 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1826 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25077 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11571 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5626 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4429 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31687 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4402 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27473 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37776 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36697 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2232 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4722 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8896 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3510 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11490 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14891 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (908 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18504 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:01:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20123 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3773 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8165 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5594 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4673 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38652 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2333 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4388 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2838 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2472 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6855 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5732 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21128 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2876 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16100 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37747 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3009 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27913 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3608 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27782 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3741 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38985 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11130 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16656 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33402 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (960 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23729 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:01:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2875 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14420 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3296 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39491 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11783 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6711 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7470 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2564 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19455 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20729 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36873 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2691 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6178 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1000 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18443 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7071 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2788 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28864 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28587 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2822 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18017 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14582 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12548 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11429 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20243 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:01:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7811 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15942 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42981 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26689 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6056 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4990 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5769 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13703 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43459 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33376 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (945 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10647 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5902 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27889 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (79869 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25498 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2074 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4287 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19959 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9760 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8738 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17914 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8660 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37936 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10208 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2816 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43489 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:01:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6187 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37499 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32400 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8589 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31584 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27928 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11550 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2776 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6261 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31162 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9143 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27613 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12392 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19920 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3328 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5032 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6228 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25829 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12060 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9220 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20742 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22755 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39088 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17267 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3192 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34634 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11065 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29281 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:01:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5968 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3704 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:01:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4154 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17885 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29943 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10858 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4463 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27340 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19532 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12232 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34440 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29657 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15527 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14280 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35029 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15458 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1954 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2532 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9219 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28901 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39646 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8076 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21220 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6243 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5142 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13449 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40566 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38096 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1370 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:02:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3765 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3304 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8560 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9570 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5932 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (941 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13313 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24569 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5303 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14614 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40696 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1854 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1695 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3426 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1996 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12227 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31170 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6335 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3366 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34946 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11444 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15184 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8407 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39221 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32549 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:02:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23409 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10430 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (825 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37284 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16523 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31274 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15535 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3455 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2647 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (45105 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38487 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3510 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14848 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5752 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12416 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7183 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20380 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15349 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14803 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5286 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1594 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40005 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5746 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19829 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2662 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:02:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18611 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3638 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2257 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10966 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18984 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1871 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17947 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33882 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3929 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6820 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7881 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2972 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39839 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5005 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18754 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13926 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (62501 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38339 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2413 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7219 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37005 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4613 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5695 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3282 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3141 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8757 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14962 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10531 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33417 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14884 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10092 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:02:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (932 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5094 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2428 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1503 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21825 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (871 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33369 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6122 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2139 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37971 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2202 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8441 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33826 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4492 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13930 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6456 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15205 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7266 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13363 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32898 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38995 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4587 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16562 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15858 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9209 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20232 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3360 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:02:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16676 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2334 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18794 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8223 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4965 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41013 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27177 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1703 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18000 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39062 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5160 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19008 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4542 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41101 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29500 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (51739 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8295 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9076 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3446 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34873 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (47866 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23102 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:02:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20821 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22541 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21981 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21584 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21965 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9257 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6419 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31158 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36224 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20916 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26143 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3224 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7706 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40381 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1505 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18962 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8355 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (938 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8942 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8046 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12087 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9667 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40271 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (824 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40310 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:02:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6433 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16357 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21906 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28233 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22102 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15253 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25511 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11418 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (55806 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19050 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2703 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33389 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5867 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5263 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4173 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27788 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10879 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41143 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3752 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32619 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15778 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13875 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22633 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40624 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27963 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29263 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30425 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9245 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:02:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11072 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30904 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28924 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1554 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16581 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (969 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1991 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38741 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:02:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10848 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (46700 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35577 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10517 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19132 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5094 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10263 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24074 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36161 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21865 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31096 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3482 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2894 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2216 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2266 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6679 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36254 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38252 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21462 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7146 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16162 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4721 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40350 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:03:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15999 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (872 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39967 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2787 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25573 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18408 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40197 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11418 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27300 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27769 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36850 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31391 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2927 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3293 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2809 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21830 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4756 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5999 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42060 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38562 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30684 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8008 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33288 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3591 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22138 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22291 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38903 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28621 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29197 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21412 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17825 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12620 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24574 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:03:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22805 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1859 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17549 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6054 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34174 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24425 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3060 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35646 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5212 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15536 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9269 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36285 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34885 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16760 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17940 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25400 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34421 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5956 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30230 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37623 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3435 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2045 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19584 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14768 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:03:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1864 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15418 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40756 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4057 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24843 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5247 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11829 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34732 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23992 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8377 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30358 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33986 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8980 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8548 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26916 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7742 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42550 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8271 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29107 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39805 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4415 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19117 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1940 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32251 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27044 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12763 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9817 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8282 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29496 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:03:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24830 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4101 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13931 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43119 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (54709 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21718 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12449 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3246 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (757 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7916 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12311 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4084 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11833 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34519 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39801 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10271 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8116 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36370 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11978 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6787 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42468 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10136 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37208 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21458 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5972 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14682 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8489 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8598 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:03:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22493 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17107 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38551 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17161 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6080 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2872 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4626 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19635 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17914 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38917 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19084 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2268 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20974 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13373 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16343 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3662 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39242 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41083 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3877 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21050 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4103 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1764 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1906 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4974 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10645 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38610 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:03:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43413 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26466 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6480 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32318 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41008 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2185 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10842 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6739 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5949 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1906 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4403 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4180 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43312 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4430 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13222 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6446 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (58877 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9069 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1792 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9249 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24259 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42711 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7696 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7122 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18061 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32077 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11011 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:03:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7253 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36432 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43939 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22230 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6228 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37548 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14825 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20385 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3053 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41369 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16618 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:03:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37341 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34642 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1014 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1863 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24473 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22687 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21590 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6184 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29735 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36879 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40138 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38126 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5096 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7571 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:04:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35302 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5026 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2716 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4150 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12633 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40085 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27579 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11276 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3071 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14595 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37945 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7715 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14616 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11389 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31436 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17433 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19413 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22027 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17420 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10776 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1882 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32630 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5082 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14105 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16301 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8267 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15035 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (68228 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7157 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27616 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:04:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42798 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38269 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9493 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38469 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27325 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3413 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34472 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26330 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39565 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9204 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3555 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21043 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4985 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6234 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13534 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37805 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25292 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20825 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7266 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38880 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30163 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2611 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:04:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36285 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22459 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17038 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26112 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3664 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4741 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42608 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34138 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22884 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11718 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6897 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18851 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21235 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3786 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12642 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22530 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18599 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9869 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16069 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17803 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35266 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12142 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7445 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23104 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1012 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5094 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:04:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36589 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41743 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15493 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3849 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25549 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23673 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20536 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30131 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (947 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4157 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32295 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31170 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3587 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14423 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23653 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8809 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21663 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17127 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18252 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10993 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1833 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40353 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30271 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2404 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38406 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:04:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12345 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1635 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6112 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2755 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2726 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8329 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20507 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15202 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3730 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12532 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1484 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39429 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30495 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1975 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28204 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11785 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41095 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10913 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (44962 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5730 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14077 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29507 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16305 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6270 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37349 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34567 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7868 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:04:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39844 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31253 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9738 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41043 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17918 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8370 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26698 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15746 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3519 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2410 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19415 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10647 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18713 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6086 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7597 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2573 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8347 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3286 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1650 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12005 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43043 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2273 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27534 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14070 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2708 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8747 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26073 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24581 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:04:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18241 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20971 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (862 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5585 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34380 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3753 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17432 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2988 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4511 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7188 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10143 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39604 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2829 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (956 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34651 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4085 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10545 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18715 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2810 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9196 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12259 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43815 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29675 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5887 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7452 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10715 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34334 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:04:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13544 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32786 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41249 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:04:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5965 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16852 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21422 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6762 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1751 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27265 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43318 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1851 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42587 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15845 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10370 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2360 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5922 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7882 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18268 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5899 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10611 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13477 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13921 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6245 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26471 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:05:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13101 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14257 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3904 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4017 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11879 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4747 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27199 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2823 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24564 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4052 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2898 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (70445 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5094 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9746 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37954 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7557 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2241 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8578 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12550 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37963 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13862 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1813 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8093 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4176 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32977 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4317 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:05:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23567 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19580 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21729 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6084 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3415 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6813 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39241 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1677 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13612 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4389 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36651 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21617 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6992 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41514 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2984 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19624 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5373 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22669 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30241 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43210 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20255 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2323 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19986 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5891 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24324 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9230 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17381 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39200 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17141 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24602 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1608 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:05:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11020 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11963 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4942 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24577 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (44498 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5999 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38794 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3669 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11160 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4794 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2709 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4207 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34531 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39083 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3414 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4574 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5413 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9162 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14552 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15927 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20503 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5145 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5485 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3178 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10550 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:05:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23254 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38236 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8680 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28699 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33658 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2412 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7003 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2047 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4307 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20389 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2835 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11600 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3166 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12742 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1892 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6606 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3699 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23792 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12659 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13632 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11995 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2617 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5284 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (67917 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33207 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14581 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3184 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11251 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21891 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:05:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20054 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19131 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11134 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17520 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1871 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22943 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6122 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33489 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (863 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (850 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12655 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34478 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6308 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34448 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4664 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15582 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13754 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21723 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41584 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1686 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38228 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32041 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35571 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33187 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19546 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17954 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27531 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1938 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1619 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4827 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:05:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9707 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14920 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4970 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7157 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42997 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21405 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21883 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22345 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3159 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10319 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3248 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5595 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3871 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4167 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35521 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (916 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43224 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12725 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2095 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9131 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7871 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21221 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37899 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42261 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26576 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28098 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9587 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32271 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:05:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20252 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28348 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18551 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8750 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14481 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3614 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23135 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41514 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6171 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37286 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3413 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37829 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3765 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1859 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5961 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37590 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8674 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19656 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5813 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32233 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3421 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7072 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34988 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9068 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5098 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:05:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20123 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42245 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6178 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3867 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27416 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6027 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20936 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8757 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14336 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40994 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21271 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12284 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15546 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35897 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (871 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2271 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37565 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:05:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8405 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14910 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38504 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8056 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2864 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11235 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26194 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2257 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22513 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33339 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32084 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:06:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9384 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5470 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40761 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40938 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11324 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19015 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6554 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19244 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39871 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4176 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14475 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (809 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43479 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9798 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39598 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29451 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20659 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3488 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42140 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3583 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38967 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20924 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22444 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5636 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14610 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42716 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17800 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:06:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37462 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9378 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35319 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22728 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26088 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13413 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8662 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22695 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39705 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38766 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4490 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14882 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41325 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4167 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22398 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (44152 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17947 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3818 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25777 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (48483 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6074 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15105 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7385 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1897 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10721 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2769 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:06:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22386 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21478 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4089 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2193 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39984 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18763 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6444 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6199 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4979 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34541 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18519 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2602 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3302 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38454 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2576 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41132 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36630 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10586 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13211 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5339 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7876 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19048 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4165 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20807 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2611 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6935 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25918 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19299 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:06:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1740 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2943 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6365 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2641 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15353 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34827 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42393 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17380 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6450 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26454 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3210 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1589 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (45617 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40405 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23000 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22441 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4349 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23402 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14220 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8732 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24843 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5145 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3552 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3432 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4522 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:06:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10333 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18017 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39851 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10950 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3859 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26172 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1018 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22134 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8467 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14768 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19720 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10163 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (988 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13428 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20290 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26955 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (914 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40315 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14768 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4919 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15916 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32173 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38741 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13744 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13465 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1558 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22884 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5077 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2726 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9579 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4350 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18903 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:06:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4066 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22553 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7588 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43489 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9870 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3494 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12038 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30843 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23246 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35907 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23772 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34059 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (128737 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35342 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39215 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40667 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2949 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9006 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23057 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22427 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14863 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16032 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16510 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:06:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17605 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2668 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8224 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17624 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3982 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36999 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1643 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (51123 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26022 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38206 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14885 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4066 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16943 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10118 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21495 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9951 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26143 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18808 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39405 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20123 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8051 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36991 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25250 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36813 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42722 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26410 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:06:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19274 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7492 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4133 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (874 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1892 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24721 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15147 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21548 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:06:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15068 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17369 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4102 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3598 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23275 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2712 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8892 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22143 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21953 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13399 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39763 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33335 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23259 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40987 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1576 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15184 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21556 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21903 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39431 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:07:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (950 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40508 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41145 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13511 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (708 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3866 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11779 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32714 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2673 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (942 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25752 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9505 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20092 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4641 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17609 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8076 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20100 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36896 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12854 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6806 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24410 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15622 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37575 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16296 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5104 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38794 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6234 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5220 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20542 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14781 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:07:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6045 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10261 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17625 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30394 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11526 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12842 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7827 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18333 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23410 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16525 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15358 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40967 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7740 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9852 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11184 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14481 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4440 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8898 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29653 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40635 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28703 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17049 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12825 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4848 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2641 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15902 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17635 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28098 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:07:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5527 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11323 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6067 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4637 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9147 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17292 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34385 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14883 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13073 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30818 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22486 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18509 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11095 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3874 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28273 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9334 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (913 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2969 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3435 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12489 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18765 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2847 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36314 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26608 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11869 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3628 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27293 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39183 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:07:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10518 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27590 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31879 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21882 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31535 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38165 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2719 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36333 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11931 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40290 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8634 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22895 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16119 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32897 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36674 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13101 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10109 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38872 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41082 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4075 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26781 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7855 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12529 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1615 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15845 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39909 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:07:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18325 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8929 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35796 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33061 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26945 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9525 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28338 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27500 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8765 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18491 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14775 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31405 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10680 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24658 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15773 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23280 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37077 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20653 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34202 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21105 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (45196 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35406 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40042 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24293 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29470 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4824 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:07:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24732 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5795 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15906 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9077 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5166 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11584 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21560 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25397 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2559 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20105 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1523 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24399 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3319 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22556 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3621 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13998 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4066 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41522 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36157 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12052 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20710 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39724 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17594 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14494 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37518 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24110 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9561 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2018 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:07:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15496 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40572 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43667 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31235 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40813 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3462 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12280 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18017 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13965 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21396 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16364 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7988 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23299 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3198 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7865 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27302 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6667 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20357 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:07:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15319 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20036 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (46470 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (991 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4531 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8403 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2090 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24148 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:08:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23249 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22729 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8613 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38788 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17216 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16175 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8745 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40654 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13843 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11324 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1912 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8285 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14566 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6036 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10359 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43953 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13915 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2076 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3454 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19734 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19630 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2428 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6858 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34819 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10513 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25247 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20705 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27752 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:08:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5324 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15490 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17724 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38676 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15093 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26111 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7341 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17772 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4721 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38578 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12005 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36949 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19478 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8149 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23114 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13194 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42357 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19804 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31813 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7140 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26576 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3823 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (45573 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4457 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35174 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3593 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5550 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22160 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43963 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2728 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:08:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8313 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7312 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11967 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36976 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43376 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28373 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5859 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20519 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14670 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11874 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2184 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21466 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25744 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26299 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36718 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3528 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26216 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7936 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4351 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27285 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28524 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (828 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7007 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6522 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24734 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16581 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2146 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:08:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18332 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28857 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36264 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26060 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2148 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37378 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21455 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35208 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42007 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28889 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21919 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41141 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3591 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23480 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5722 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40231 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24865 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11831 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1651 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2732 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41471 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42711 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8508 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38181 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26158 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1703 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15748 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22505 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33005 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:08:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1598 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42320 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26796 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24577 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16781 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34513 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6944 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (828 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21846 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3117 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10046 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22628 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3872 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19508 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2617 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21522 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22697 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5091 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7102 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6296 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:08:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1710 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20118 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9058 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16228 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8060 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38386 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3743 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36666 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1652 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6889 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32690 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (52599 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37021 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7189 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14830 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20674 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6181 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2383 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20869 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38753 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7332 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35985 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5894 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1000 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3818 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40448 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:08:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29952 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2714 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (979 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32812 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24529 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17914 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24153 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2832 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15912 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23707 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40058 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1785 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (827 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14757 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14726 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23204 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1908 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5189 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3690 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4371 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33442 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3885 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43336 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3512 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40913 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14336 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:08:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11420 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4831 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16357 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21462 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43897 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36229 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10465 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36453 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22319 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23534 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:08:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26334 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21929 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18476 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16344 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38463 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4976 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2283 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4247 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20896 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36986 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5665 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28429 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5681 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:09:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2136 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13306 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8981 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10464 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (996 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2193 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5072 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41924 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9534 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19091 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5314 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3331 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2335 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18282 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32228 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3224 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9682 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15972 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21487 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11907 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6836 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13008 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2871 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14918 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:09:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40639 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9554 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17362 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12601 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15211 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1744 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8892 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11950 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21571 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15822 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25899 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18380 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17989 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13909 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41145 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30003 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8521 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (860 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14680 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3575 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16959 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20922 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30423 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3638 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4180 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1491 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:09:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1768 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3557 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5045 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2404 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39576 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28791 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12710 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5065 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35926 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8299 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4066 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13301 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2737 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4402 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39592 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24547 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25366 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2896 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35577 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40081 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20737 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16043 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4966 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29098 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9974 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28098 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11244 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23378 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:09:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1722 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22824 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4938 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32919 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39221 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36552 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43192 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27743 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2037 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28845 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4615 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43773 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21230 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5767 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2656 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2668 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7896 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28819 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40771 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1724 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16000 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6583 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5517 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15093 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14747 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35244 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12522 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6948 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:09:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (45090 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22941 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38235 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42007 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21593 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8581 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20022 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18109 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6604 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26495 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26470 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9118 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27690 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12341 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3202 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1602 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9694 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2952 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10858 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2231 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2696 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30928 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41076 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (850 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18109 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35677 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16425 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17657 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39055 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:09:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (44097 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3455 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24247 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16570 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16636 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11417 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2727 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2446 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16624 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7904 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7700 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3465 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13831 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4161 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6612 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29155 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34661 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3669 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21906 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21427 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14379 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2691 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39860 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12526 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9047 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13077 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12608 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19647 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:09:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34250 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18642 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16440 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1720 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40303 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31072 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39631 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4517 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (48777 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (927 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5923 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2180 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26169 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6288 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9122 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10295 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28322 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2442 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2463 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15553 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23428 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9135 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10515 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (55265 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30657 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16257 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2080 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29710 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:09:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1732 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30580 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34669 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20847 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38686 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27629 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3112 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2430 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21147 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30136 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2624 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5936 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10294 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (873 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1013 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17289 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6053 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1667 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6944 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9071 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28175 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38161 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12820 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7141 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8422 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35147 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3677 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:09:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3116 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:09:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (45051 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6243 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8534 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5712 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (880 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30843 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6434 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5618 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35499 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2564 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10814 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10072 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18838 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40521 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5459 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (44989 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25098 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (753 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15964 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8732 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16819 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9028 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19178 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37605 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39739 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28817 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3307 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9327 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27874 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:10:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41679 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14766 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2303 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3812 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6854 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3551 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20594 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35644 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27696 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12836 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32587 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24908 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4019 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22576 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13258 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6732 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3484 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37966 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18432 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38111 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32210 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (858 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19128 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4614 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9371 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26034 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41964 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8128 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:10:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31626 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34352 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4509 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18520 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18593 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11523 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18102 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13189 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3275 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27272 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (53390 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13370 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41818 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3275 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2733 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17331 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9333 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7742 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3325 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10907 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4989 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14918 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10530 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6995 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9198 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1903 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24943 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15081 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39284 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16480 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:10:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25260 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31660 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12980 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21963 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17200 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19263 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28818 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (49206 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7276 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18019 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27165 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21436 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3438 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28157 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16375 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4547 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7974 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32688 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20644 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28955 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18642 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23140 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3866 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13933 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17034 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3241 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:10:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32817 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38679 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (45455 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17059 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37550 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5166 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40866 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37814 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38920 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2676 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1892 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15531 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1636 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13131 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12044 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8018 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (995 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26063 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10832 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9785 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (941 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4505 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4942 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11035 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4710 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17299 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:10:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14739 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26054 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (989 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1664 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13962 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4043 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25087 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36339 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4448 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32634 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6197 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3177 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6355 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30096 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9125 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9106 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31956 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41651 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11802 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2575 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39483 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26373 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11038 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3845 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10678 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27854 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:10:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2769 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (989 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2565 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2179 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4514 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18444 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19438 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33010 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20555 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36545 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5284 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23319 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (909 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8842 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1522 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9513 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8791 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3603 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40445 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7316 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3008 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41402 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27737 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43449 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2550 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35419 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10723 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25271 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32862 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19413 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:10:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36000 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2702 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7797 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5874 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25598 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12111 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30531 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25077 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6782 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39097 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8729 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8462 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4966 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3080 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (65902 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (915 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5720 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37412 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34907 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12958 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4101 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27671 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38257 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19076 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:10:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30478 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36909 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41380 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23342 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:11:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38826 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2714 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7471 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12106 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8270 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37702 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4833 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7191 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3555 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14151 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27554 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20206 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (36487 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3141 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28271 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22533 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1010 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8806 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2417 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29013 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1925 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:06 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39644 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5144 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11240 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8285 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:07 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (35447 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28610 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:11:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3413 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7496 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25844 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:08 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39884 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3032 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11601 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:09 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (16592 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33652 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20512 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15197 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12070 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:10 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5408 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40007 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10160 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (800 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:11 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13426 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10806 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26624 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1630 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:12 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6606 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43571 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1340 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (926 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (975 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2081 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:13 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19929 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22744 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4776 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:14 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39756 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:11:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42462 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:15 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33277 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6701 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15001 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12818 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21039 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3360 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:16 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2366 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28177 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7658 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:17 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29689 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14895 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:18 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17543 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9973 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6782 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15029 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:19 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15584 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40284 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:20 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5568 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41224 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5347 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (33128 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1432 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1744 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1631 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:21 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3796 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10500 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14908 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (41931 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:22 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:11:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11825 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12355 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4595 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1797 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39980 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13597 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10773 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:24 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7604 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38979 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (20569 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:25 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11925 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22455 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7451 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25382 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:26 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8440 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17670 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9751 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18928 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:27 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22092 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (52060 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11719 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:28 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2663 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7993 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5138 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (39746 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10654 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:29 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7919 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10858 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24831 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:11:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31681 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19601 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:31 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28080 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27866 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:32 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32983 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42954 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:33 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (43093 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:34 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23702 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34718 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3927 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4960 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3743 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8371 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11858 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:35 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6301 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15955 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15675 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2100 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:36 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26143 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19230 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1803 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3941 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:37 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18471 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21328 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4936 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30789 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:11:38 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7847 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18017 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29319 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:39 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (17219 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2166 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7776 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4307 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:40 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28245 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37836 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5444 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11834 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2354 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:41 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14555 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7345 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (5025 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30003 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:42 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2262 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14918 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3131 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (42711 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:43 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18814 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31757 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (3498 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2297 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18595 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:44 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1763 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40119 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:11:45 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13709 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:46 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24557 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (19513 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (22000 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:47 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14424 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (34944 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:48 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (18625 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (10993 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:49 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26121 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32091 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7071 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11700 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6951 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2624 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:50 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (24548 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:51 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (29111 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (51066 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:52 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7202 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37805 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1635 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (32041 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2120 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:53 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12703 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (50149 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14161 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:54 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2570 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27742 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7352 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2435 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (31136 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:11:55 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9877 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27788 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13738 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:56 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (9476 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (30895 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:57 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (2795 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (37252 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (40088 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:58 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7558 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11116 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (12684 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:11:59 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (28664 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (21857 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (13671 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (11171 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:00 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (26566 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1566 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8906 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6598 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:01 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (15269 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (38042 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (27196 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6662 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (23051 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:02 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (4835 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14743 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6330 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (786 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/18/2020 13:12:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (8510 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:03 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (7204 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (44020 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:04 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (14301 > 512). Running this sequence through the model will result in indexing errors\n",
      "01/18/2020 13:12:05 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (25914 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MAX_SEQ_LENGTH=100\n",
    "\n",
    "class BertInputItem(object):\n",
    "    \"\"\"An item with all the necessary attributes for finetuning BERT.\"\"\"\n",
    "\n",
    "    def __init__(self, text, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.text = text\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        \n",
    "\n",
    "def convert_examples_to_inputs(example_texts, example_labels, label2idx, max_seq_length, tokenizer, verbose=0):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    \n",
    "    input_items = []\n",
    "    examples = zip(example_texts, example_labels)\n",
    "    for (ex_index, (text, label)) in enumerate(examples):\n",
    "\n",
    "        # Create a list of token ids\n",
    "        input_ids = tokenizer.encode(f\"[CLS] {text} [SEP]\")\n",
    "        if len(input_ids) > max_seq_length:\n",
    "            input_ids = input_ids[:max_seq_length]\n",
    "\n",
    "        # All our tokens are in the first input segment (id 0).\n",
    "        segment_ids = [0] * len(input_ids)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = label2idx[label]\n",
    "\n",
    "        input_items.append(\n",
    "            BertInputItem(text=text,\n",
    "                          input_ids=input_ids,\n",
    "                          input_mask=input_mask,\n",
    "                          segment_ids=segment_ids,\n",
    "                          label_id=label_id))\n",
    "\n",
    "        \n",
    "    return input_items\n",
    "\n",
    "train_features = convert_examples_to_inputs(train_texts, train_labels, label2idx, MAX_SEQ_LENGTH, tokenizer, verbose=0)\n",
    "dev_features = convert_examples_to_inputs(dev_texts, dev_labels, label2idx, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = convert_examples_to_inputs(test_texts, test_labels, label2idx, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we're going to initialize a data loader for our training, development and testing data. This data loader puts all our data in tensors and will allow us to iterate over them during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "\n",
    "def get_data_loader(features, max_seq_length, batch_size, shuffle=True): \n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "    dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = get_data_loader(train_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=True)\n",
    "dev_dataloader = get_data_loader(dev_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = get_data_loader(test_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to write our evaluation method. This method takes as input a model and a data loader with the data we would like to evaluate on. For each batch, it computes the output of the model and the loss. We use this output to compute the obtained precision, recall and F-score. During training, we will print the simple numbers. When we evaluate on the test set, we will output a full classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    predicted_labels, correct_labels = [], []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss, logits = model(input_ids, attention_mask=input_mask,\n",
    "                                          token_type_ids=segment_ids, labels=label_ids)\n",
    "\n",
    "        outputs = np.argmax(logits.to('cpu'), axis=1)\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        \n",
    "        predicted_labels += list(outputs)\n",
    "        correct_labels += list(label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    \n",
    "    correct_labels = np.array(correct_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "        \n",
    "    return eval_loss, correct_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to start training. We're going to use the AdamW optimizer with a base learning rate of 5e-5, and train for a maximum of 100 epochs. Here are some additional things to note: \n",
    "\n",
    "- Gradient Accumulation allows us to keep our batches small enough to fit into the memory of our GPU, while getting the advantages of using larger batch sizes. In practice, it means we sum the gradients of several batches, before we perform a step of gradient descent. \n",
    "- We use the WarmupLinearScheduler to vary our learning rate during the training process. First, we're going to start with a small learning rate, which increases linearly during the warmup stage. Afterwards it slowly decreases again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "NUM_TRAIN_EPOCHS = 20\n",
    "LEARNING_RATE = 5e-5\n",
    "WARMUP_PROPORTION = 0.1\n",
    "MAX_GRAD_NORM = 5\n",
    "\n",
    "num_train_steps = int(len(train_dataloader.dataset) / BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(WARMUP_PROPORTION * num_train_steps)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, correct_bias=False)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_train_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're finally ready to train our model. At each epoch, we're going to train it on our training data and evaluate it on the development data. We keep a history of the loss, and stop training when the loss on the development set doesn't improve for a certain number of steps (we call this number our `patience`). Whenever the development loss of our model improves, we save it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A/Users/septem/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed29976e0a245dc98b22fceee76ea48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=252, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74627818a63c4436a8928147e14fdc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=28, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: []\n",
      "Dev loss: 0.6920232496091298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   5%|▌         | 1/20 [54:23<17:13:32, 3263.82s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae08d9210c544ab857d31f73ab91369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=252, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a5a19a5e7a4c18ac540c283464eed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=28, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [0.6920232496091298]\n",
      "Dev loss: 0.6838647723197937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  10%|█         | 2/20 [1:51:50<16:35:34, 3318.58s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7da28c60e84cb680268fc2c4d4fd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=252, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab4442b31bb4115a38fb81a5b2e2b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=28, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  15%|█▌        | 3/20 [3:35:40<19:47:44, 4192.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [0.6920232496091298, 0.6838647723197937]\n",
      "Dev loss: 0.684954006757055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603ce0cb5cbf4107b31b1d49f9b793da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=252, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4d271b55b14b0099defcf6f95970dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=28, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [0.6920232496091298, 0.6838647723197937, 0.684954006757055]\n",
      "Dev loss: 0.6896078437566757\n",
      "No improvement on development set. Finish training.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "OUTPUT_DIR = \"/tmp/\"\n",
    "MODEL_FILE_NAME = \"pytorch_model.bin\"\n",
    "PATIENCE = 2\n",
    "\n",
    "loss_history = []\n",
    "no_improvement = 0\n",
    "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=label_ids)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)  \n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            \n",
    "    dev_loss, _, _ = evaluate(model, dev_dataloader)\n",
    "    \n",
    "    print(\"Loss history:\", loss_history)\n",
    "    print(\"Dev loss:\", dev_loss)\n",
    "    \n",
    "    if len(loss_history) == 0 or dev_loss < min(loss_history):\n",
    "        no_improvement = 0\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        output_model_file = os.path.join(OUTPUT_DIR, MODEL_FILE_NAME)\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "    \n",
    "    if no_improvement >= PATIENCE: \n",
    "        print(\"No improvement on development set. Finish training.\")\n",
    "        break\n",
    "        \n",
    "    \n",
    "    loss_history.append(dev_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate the model on some documents it has never seen. We'll load our best model and have it predict the labels for all documents in our data. We'll compute its precision, recall and F-score for the training, development and test set and print a full classification report for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/20/2020 00:01:51 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /Users/septem/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "01/20/2020 00:01:51 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "01/20/2020 00:01:51 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /Users/septem/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "/Users/septem/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15307148d18e4e1fa551771f5188f4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=252, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c828d0c4d594b8f9e06731c574fc441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=28, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501d95cda2794cb89280b9b83288b85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=32, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance: (0.5376771947276797, 0.5376771947276797, 0.5376771947276797, None)\n",
      "Development performance: (0.5682326621923938, 0.5682326621923938, 0.5682326621923938, None)\n",
      "Test performance: (0.5674044265593562, 0.5674044265593562, 0.5674044265593562, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      others       0.00      0.00      0.00       215\n",
      "       innov       0.57      1.00      0.72       282\n",
      "\n",
      "    accuracy                           0.57       497\n",
      "   macro avg       0.28      0.50      0.36       497\n",
      "weighted avg       0.32      0.57      0.41       497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/septem/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_state_dict = torch.load(os.path.join(OUTPUT_DIR, MODEL_FILE_NAME), map_location=lambda storage, loc: storage)\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, state_dict=model_state_dict, num_labels = len(target_names))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "_, train_correct, train_predicted = evaluate(model, train_dataloader)\n",
    "_, dev_correct, dev_predicted = evaluate(model, dev_dataloader)\n",
    "_, test_correct, test_predicted = evaluate(model, test_dataloader)\n",
    "\n",
    "print(\"Training performance:\", precision_recall_fscore_support(train_correct, train_predicted, average=\"micro\"))\n",
    "print(\"Development performance:\", precision_recall_fscore_support(dev_correct, dev_predicted, average=\"micro\"))\n",
    "print(\"Test performance:\", precision_recall_fscore_support(test_correct, test_predicted, average=\"micro\"))\n",
    "\n",
    "bert_accuracy = np.mean(test_predicted == test_correct)\n",
    "\n",
    "print(classification_report(test_correct, test_predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that BERT obtains an accuracy of around 70% on the test data. This is around 8% more than our initial baseline classifier. This confirms that BERT's transfer learning helps us achieve significantly higher accuracies for small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f46ec397128>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({\"accuracy\": {\"baseline\": baseline_accuracy, \"BERT\": bert_accuracy}})\n",
    "plt.rcParams['figure.figsize'] = (7,4)\n",
    "df.plot(kind=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
